\documentclass[a4paper,twoside,11pt]{article}

\input{packages}		% Подключаемые пакеты
\usepackage{newprog1e}  % Стили

\pgfplotsset{compat=1.14}

\tolerance=1000

\newcommand{\defi}{\stackrel{\mathrm{def}}{=}}

\numberwithin{equation}{section}
\newtheorem{theorem}{Теорема}

\newtheorem{definition}{Definition}
\newtheorem{theorem_ru}{Теорема}


\journalnumber{4}
\curyear{2018}
\authorlist{С. П. Арсеев, А. С. Конушин, В. С. Лютов}
\titlehead{РАСПОЗНАВАНИЕ ЧЕЛОВЕКА ПО ПОХОДКЕ И ВНЕШНОСТИ}
\headerdef

\udk{004.932.72'1}
\rubrika{Анализ данных}
\dateinput{31.01.2018}

\rusabstr{В работе рассматривается задача идентификации человека в видеопоследовательности. Для нее предлагается два взаимодополняющих решения, которые могут быть применены в различных ситуациях: распознавание по походке и по внешнему виду. Для распознавания по походке рассматриваются три вида признаков: антропометрические признаки, то есть длины сегментов скелета и высота человека; признаки относительных расстояний, получаемые из разности координат различных точек скелета; а также признаки движения, основанные на смещении узла скелета между двумя соседними кадрами. Представлены два вида алгоритма распознавания по походке: использующий данные о глубине и работающий только с видеопоследовательностью. Для распознавания по внешности предлагается алгоритм глубинного обучения, строящий бинарные признаки изображения. Оба алгоритма проверены на двух эталонных коллекциях. Также описывается перенос протокола тестирования с одной эталонной коллекции на другую для проверки переносимости обученной модели.
}

\author{
{\bfseries С. Арсеев$^1$, А. С. Конушин$^{1,2}$, В. С. Лютов$^1$}
\\ {\itshape $^1$Московский государственный университет им. М. В. Ломоносова}
\\ {\slshape 1199991} {\itshape Москва, ГСП-1, Ленинские горы, д.} {\slshape 1}
\\ {\itshape $^2$Национальный исследовательский университет Высшая школа экономики}
\\ {\slshape 101000}, {\itshape г. Москва, ул. Мясницкая, д.} {\slshape 20}
\\ {\itshape E-mail: 9413serg@gmail.com, anton.konushin@graphics.cs.msu.ru, vladimir.lutov@graphics.cs.msu.ru }}

\title{РАСПОЗНАВАНИЕ ЧЕЛОВЕКА ПО ПОХОДКЕ И ВНЕШНОСТИ}
%\thanks{~}

\date{31.01.2018}

\begin{document}

\maketitle
\setcounter{page}{3}

% \begin{multicols*}{2}

\section{Введение}

В данной работе рассматривается задача повторной идентификации человека в видео: автоматическое сопоставление обнаружений людей со списком известных людей, заранее занесенных в галлерею. Данная задача находит применение в автоматизации видеонаблюдения и используется для сопоставления людей между разными камерами в криминалистике и в поиске в видеоархивах. Сейчас основной способ идентификации человека в видео -- по лицу. Этот способ неприменим в сценариях, когда лицо недостаточно видно из-за ракурса камеры, ее разрешения, а также в случае, если лицо намеренно закрывают. В этих ситуациях мы можем полагаться только на внешность в целом и на движение, например, походку.

Целью работы является преодаление этих ограничений путем разработки и улучшения взаимодополняющих методов идентификации человека в видео: распознавание человека по походке и построение бинарных дескрипторов изображения человека.

Распознавание по внешнему виду применяется в первую очередь для повторной идентификации человека в алгоритмах сопровождения~\cite{kuplyakov2017markov}. Если человек в процессе движения на какое-то время перекрывается элементом сцены, то траектория его движения разбивается на два отдельных фрагмента~\cite{shal2016estimation}. Для объединения фрагментов в единую траекторию необходимо связать по внешности человека более поздний фрагмент с более ранним. Поскольку решать подобные задачи необходимо постоянно в процессе сопровождения, то скорость имеет очень важное значение, и использование бинарных дескрипторов позволяет повысить производительность.  

В некоторых сценариях внешний вид человека на изображении не может служить надёжным основанием для его идентификации, поскольку этот признак не обеспечивает ни надёжного разделения различных людей (люди могут носить похожую одежду или же полностью одинаковую в случае униформы), ни устойчивости на длительном промежутке времени (когда человек меняет одежду, меняется и его внешний вид). Тогда применяется распознавание по походке: строят признаки, анализируя движения человека в видеопоследовательности, содержащей запись его ходьбы. Эта задача относится к области биометрии, т.е. распознавания человека по физическим или поведенческим чертам. Отличительной особенностью распознавания человека по походке является удобство его применения: походка человека – это признак, основанный на его действиях, а не на внешнем виде, и изменения внешнего вида человека  (например, одежды) слабо сказываются на его походке.

\section{Обзор существующих методов}

На вход алгоритму повторной идентификации подается результат работы алгоритма обнаружения людей -- обнаружения. Обнаружения -- выделенные из полученных со статических камер изображений прямоугольники, содержащие изображения людей. В случае идентификации по походке это не прямоугольники, а последовательность прямоугольников, полученная из последовательных кадров. Требуется сопоставить обнаружения с галереей изображений или, иначе говоря, сравненить дескриптор обнаружения с дескрипторами в галерее. Обычно алгоритм дает ряд наиболее близких по некоторой метрике людей, отсортированных в порядке увеличения расстояния.

Эта задача является частным случаем задачи идентификации человека. Она традиционно решается за два этапа: построение дескриптора изображения человека и поиск по базе дескрипторов~\cite{karanam2016systematic}. Пример работы приведен на рисунке~\ref{rankexample}. В данной работе рассматривается подзадача построения дескриптора.

\begin{figure}[ht]
    \centering{\includegraphics[width=\linewidth]{arseev-image4.eps}}
    \caption{Пример работы предложенного алгоритма.}
    \label{rankexample}
\end{figure}

\subsection{Распознавание по походке}


Методы распознавания человека по походке можно разделить на две большие группы: на основе силуэта, на основе структурной модели. Методы, использующие второй подход, более устойчивы к изменениям положения камеры, а также к некоторым факторам, влияющим на силуэт и внешний вид человека. Минусом этой группы методов является высокая вычислительная сложность построения модели, что приводит к замедлению работы алгоритма. В открытом доступе отсутствуют эталонные коллекции, содержащие достаточно для методов глубинного обучения примеров походки каждого отдельного человека.

\begin{enumerate}
    \item \textbf{Методы на основе силуэта} обычно используют различные модификации алгоритма~\cite{man2006individual}. Изображение энергии походки (Gait Energy Image, GEI) получается усреднением силуэтов человека (центрированных, чтобы избежать смещения во время прохода человека мимо камеры) по всей видеопоследовательности или по циклу походки, т.е. по времени, которое требуется, чтобы сделать шаг. Признаки для классификации извлекаются из этого изображения. В работе~\cite{chhatrala2017gait} изображение энергии походки сначала трансформируется при помощи curvelet-преобразования, а затем классифицируется с помощью глубинного обучения.
    
    \item \textbf{Методы на основе модели} изначально работали с изображениями человека и различными способами строили модель его позы~\cite{bobick2001gait,lee2002gait}, но затем, с выделением задачи оценки позы человека по его изображению в отдельную задачу компьютерного зрения, набрали популярность алгоритмы, использующие уже готовую модель, построенную каким-либо внешним алгоритмом оценки позы. В частности, популярно использование сенсора Microsoft Kinect~\cite{kastaniotis2015framework,rouzbeh2015human,yang2016relative}.

\end{enumerate}

\subsection{Распознавание по внешнему виду}

Большинство методов идентификации строят дескриптор из вещественных чисел, при этом чем больше галерея, тем больше времени занимает поиск. Проблему ускорения поиска решают с помощью бинарных дескрипторов~\cite{lin2015deep}: сначала строят вещественный дескриптор достаточно высокого качества, затем на его основе строят бинарный дескриптор.

\subsubsection{Вещественные признаки}

Методы построения вещественных дескрипторов можно разбить на три группы:

\begin{enumerate}
    \item \textbf{Методы без машинного обучения} показывают наименьшую точность~\cite{karanam2016systematic,zheng2016person}.
    
    \item \textbf{Методы с машинным неглубинным обучением}: “Иерархический гауссовый дескриптор для повторной идентификации человека” GOG~\cite{matsukawa2016hierarchical} показывает наилучшую точность в данном классе~\cite{karanam2016systematic}.
    
    \item \textbf{Методы с глубинным обучением} показывают наилучшие результаты для этой задачи~\cite{hermans2017defense,zhang2017deep}, а также в других задачах компьютерного зрения, например, в задаче выделения движущихся объектов~\cite{morozov2016background}.
    
\end{enumerate}

\subsubsection{Бинарные признаки}

Для повторной идентификации существуют методы бинаризации дескрипторов~\cite{wu2017structured}. В отличии от прошлых исследований в данной работе проведено сравнение сразу нескольких методов:

\begin{enumerate}
    \item Наивная бинаризация - поэлементное сравнение исходного дескриптора с 0.
    \item Выделение наиболее значимых элементов исходного дескриптора с помощью метода случайного леса~\cite{breiman2001random}.
    \item Преобразование в пространство меньшей размерности с помощью метода главных компонент~\cite{halko2011finding}, затем бинаризация.
    \item Нейросетевые методы построения бинарных дескрипторов: алгоритм сигмоиды~\cite{lin2015deep} и его модификация DBE~\cite{liu2017end}.
\end{enumerate}

Алгоритм сигмоиды заключается в добавлении к сети, строящей вещественные дескрипторы, полносвязного слоя с сигмоидальной функцией активации. В алгоритме DBE вместо этого слоя используется последовательность из нескольких слоев:

$$f_{DBE}(x) = tanh(ReLU(BN(W_{DBE} x + b_{DBE}))),$$

%\begin{expl}
    %\where
где $f_{DBE}$ -- алгоритм DBE, $X$ -- вещественный дескриптор, $tanh(Z)$ -- поэлементный гиперболический тангенс, $ReLU(Z)$ -- поэлементный $max(0, z_i)$, $BN$ -- слой пакетной нормировки~\cite{ioffe2015batch}, $W_{DBE}, b_{DBE}$ -- оптимизируемые веса алгоритма, матрица и вектор, соответственно.
%\end{expl}

\section{Предложенный метод}

\subsection{Распознавание по походке}

Предложенный метод основан на методе, предложенном в~\cite{yang2016relative}. Каждую видеопоследовательность подвергали предобработке для построения модели оценки позы для каждого кадра (скелета), которая затем использовали для идентификации. Сенсор Microsoft Kinect строит скелет, размеченный, как показано на рисунке~\ref{kinnectskeleton}.

\begin{figure}[ht]
    \centering{\includegraphics[width=\linewidth]{arseev-image1.png}}
    \caption{Скелет Kinect.}
    \label{kinnectskeleton}
\end{figure}

Из последовательности скелетов получали признаки, которые можно разделить на три категории: антропометрические признаки (Anthropometric Features, AF), то есть длины сегментов скелета и высота человека; признаки относительных расстояний (Relative Distance Features, RDF), получаемые из разности координат различных точек скелета; а также признаки движения (Motion Features, MF), основанные на смещении узла скелета между двумя соседними кадрами. Классификацию проводили с использованием метода K ближайших соседей и метода случайных подпространств для отбора признаков.

\subsubsection{Антропометрические признаки}

Антропометрические признаки характеризуют длины сегментов скелета в трёхмерном пространстве, а также высоту человека. Через $Len(a, b)$ обозначим евклидово расстояние между узлами $a$ и $b$.

Для скелета от Kinect:

\begin{align*}
 Height =& Len(1, 2) + Len(2, 11) + Len(11, 12) + \\
         &+ \frac{Len(14, 16) + Len(13, 15)}{2} + \\
         &+ \frac{Len(16, 18) + Len(15, 17)}{2}
\end{align*}

19 значений $Len$ и значение $Height$ объединили в вектор антропометрических признаков (AF). Поскольку координаты точек модели, с которой работает алгоритм, определяются неточно из-за шумов и перекрытий, каждую компоненту вектора AF фильтровали: для неё считали среднее значение и среднеквадратичное отклонение по всем кадрам последовательности, после чего считали новое среднее значение без учёта значений с тех кадров, на которых значение этой компоненты отклоняется от среднего больше, чем на два среднеквадратичных отклонения. Получившийся вектор из новых средних значений -- это итоговый вектор AF, который использовали при классификации.

\subsubsection{Признаки относительных расстояний}

Каждый узел $a$ скелета описывается его координатами: $x_a$, $y_a$ и $z_a$ для скелетов с картой глубины.  Признаки относительных расстояний извлекали отдельно по каждой оси. Вектор RDF составили из всех расстояний, представленных в виде  $|x_a - x_b|$, где $a$ и $b$ - индексы парных узлов, например, 3 и 4 или 15 и 16, или же $a$ узел из такой пары, а  $b$ - соответствующий ему центральный узел (2 для $a$ 3-10 и 12 для 13-20). Также в него включили признаки, представляемые как $|x_c - \frac{x_a + x_b}{2}|$, где $a$ и $b$ - индексы парных узлов, а $c$ равно либо 1 (голова), либо 11 (позвоночник). Итоговый вектор RDF составили из средних значений и среднеквадратичных отклонений каждого такого расстояния по видеопоследовательности.

Для трёхмерных скелетов от Kinect вектор RDF составили из 240 элементов: в скелете 8 пар узлов, и из каждой такой пары извлекали по 10 признаков по каждой из трёх осей.

\subsubsection{Признаки движения}

Признаки движения основаны на смещении узла скелета между соседними кадрами, что является характеристикой скорости движения этого узла. Сдвиг считали не в абсолютных координатах, а относительно центральной точки скелета, что делает эти признаки устойчивыми к движению человека относительно камеры.

Признаки считали отдельно по трём осям: $x$, $y$ и $z$. В двухмерной версии алгоритма из-за отсутствия информации о глубине осей только две.

$$Mx_{a,t} = |x_{a, t} - x_{b, t} - (x_{a, t-1} - x_{b, t-1})|$$

Здесь $a$ - точка на конечности (узлы 3-10 и 13-20), а $b$ - соответствующий ей центральный узел (как при подсчёте признаков RDF).

Среднее значение (по $t$) и среднеквадратичное отклонение для каждого узла по каждой оси объединили в вектор MF. Для скелетов Kinect он состоял из 96 элементов: из каждой из 16 точек получали по два признака по каждой из трёх осей.

Эти три вида признаков проиллюстрированы на рисунке~\ref{threetypes}.

\begin{figure}[ht]
    \centering{\includegraphics[height=6.5cm]{arseev-image2.png}}
    \caption{Три типа признаков походки.}
    \label{threetypes}
\end{figure}

\subsubsection{Обработка последовательности}

Итоговый вектор признаков, состоящий из векторов AF, RDF и MF, классифицируется ансамблем из 100 классификаторов по методу K ближайших соседей с метрикой городских кварталов в качестве метрики расстояния. Итоговый вектор признаков имел достаточно большую размерность (356 признаков), и поэтому каждый классификатор использовали для классификации по подмножеству из 10 признаков.

Для оценки качества классификатора (и, соответственно, подпространства признаков, на котором он работает) использовали систему начисления баллов: классификатор выдавал пять ближайших примеров из обучающей выборки, после чего ему начисляли баллы, если среди этих примеров были примеры того же класса, что и тестовый пример: 5 баллов, если ближайший пример оказался нужного класса, 4 балла за второй ближайший и так далее до 1 балла за пятый ближайший пример в случае, если он совпадал по классу с тестовым. В случае, если среди пяти примеров несколько соответствовали тестовому по классу, баллы начисляли за каждый из них.

Чтобы избежать потери эффективности ансамбля из-за похожести отбираемых классификаторов использовали систему штрафов. При подсчёте итогового количества баллов подпространство признаков классификатора сравнивали с подпространствами признаков классификаторов, находящихся в ансамбле в данный момент. За совпадение какого-либо признака накладывали штраф в 20 баллов. Данное значение подобрали экспериментальным путём. После оценки каждых 100 случайных классификаторов ансамбль обновляли, включая в него 100 лучших классификаторов из рассмотренных и тех, которые находились в ансамбле на предыдущем шаге. Итоговый ансамбль сформировали после оценки таким способом 2000 случайных классификаторов.

На рисунке~\ref{featureusage} показано использование признаков ансамблем в трёхмерной версии алгоритма. Из диаграммы видно, что почти все признаки использовались в классификаторах, и некоторые из них использовались значительно чаще остальных. Поскольку классификаторы для ансамбля генерировали случайным образом, внешний вид этого распределения меняется при повторном построении ансамбля, но местоположение основных пиков, соответствующих наиболее значимым признакам, остаётся неизменным.

\begin{figure}[ht]
    \centering{\includegraphics[width=\linewidth]{arseev-image3.png}}
    \caption{Использование признаков походки. По оси X отложены индексы признаков в итоговом векторе: первые 240 признаков входят в RDF, следующие 20 в AF, а остальные в MF. По оси Y отложено количество классификаторов, использовавших этот признак.}
    \label{featureusage}
\end{figure}

Результаты классификации определяли путём взвешенного голосования по ансамблю. Каждый классификатор выдавал 5 наиболее вероятных меток класса, и каждому классу начисляли по 5 баллов за первое место, по 4 за второе и так далее до 1 балла за пятое место. Итоговое количество баллов, набранное каждым классом, использовали для ранжирования классов и определения конечного результата классификации.

\subsection{Распознавание по внешнему виду}

По результатам проведенного обзора в качестве базового алгоритма выбрали алгоритм VGG16, предобученный на задаче ImageNet. Он состоит из 5ти блоков сверток+max-pooling и 3 полносвязных слоев. На вход он получает изображение размером 224x224x3, на выходе -- вероятность принадлежности каждой из картинок к тому или иному классу из 1000 классов. Предложенная модификация изображена на рисунке~\ref{architecture} и подробно описана ниже. Исходный код доступен по ссылке \url{https://github.com/vslutov/reidentification}.

\begin{figure}[t]
    \centering{\includegraphics[height=\linewidth, angle=90]{arseev-image5.eps}}
    \caption{Схема предложенного алгоритма построения бинарного дескриптора внешности.}
    \label{architecture}
\end{figure}

Тренировочные данные случайным образом были разделены на обучающую и валидационную выборки. Отношение количества примеров в обучающей и валидационной выборке было равно 9/1.

\subsubsection{Адаптация под задачу повторной идентификации человека}

В алгоритме использовался размер входного изображения $128 \times 64$, поэтому были использованы только сверточные слои из предобученной на ImageNet модели VGG~\cite{simonyan2014very}. В ходе экспериментального исследования выяснилось, что при удалении самого глубокого блока сверток и max-pooling слоя точность алгоритма увеличивается. Возможно это связано с тем, что в данной задаче для алгоритма важнее низкоуровневые свойства такие как цвет и текстура одежды.

В конец сети был добавлен GlobalAveragePooling слой. Это простой способ получить низкоуровневое представление информации о картинке. Также в конец сети был добавлен слой пакетной нормировки~\cite{ioffe2015batch}. Эта модификация увеличила точность работы алгоритма и позволила провести наивную бинаризацию простым сравнением с нулем, длина хеша при такой бинаризации равна числу выходов слоя пакетной нормировки, то есть 512.

В конец сети был добавлен один полносвязный слой с функцией активации softmax и количеством нейронов равному числу классов в обучающей выборке -- для Market1501~\cite{zheng2015scalable} это 751. Этот слой называется классифицирующим, он используется только во время обучения. Во время обучения в качестве функции ошибки была использована ошибка идентификации: многоклассовая перекрестная энтропия выходов классифицирующего слоя и ожидаемого результата. Вещественный дескриптор -- выход слоя пакетной нормировки, он имел размерность 512 вещественных чисел.

\subsubsection{Обучение нейронной сети}

Для обучения использовался оптимизатор nadam~\cite{dozat2016incorporating}. Размер батча -- 128 изображений. Если в течение 4х эпох ошибка на валидационной выборке не уменьшалась, то уменьшали скорость обучения в 10 раз. Если в течение 10 эпох ошибка на валидационном наборе не уменьшалась, то обучение завршалось.

Сначала отключали обучение всех слоев, кроме последнего полносвязного и обучали до 50 эпох. Затем включали обучение всех сверточных слоев и еще раз проводли до 50 эпох обучения.

Этот метод обучения показал точность Rank~1 85\%, что сравнимо с наилучшими из известных методов решения этой задачи. Из чего можно сделать вывод, что в этой задаче низкоуровневые признаки сохраняют основную необходимую информацию и дальнейшее усложнение архитектуры нецелесообразно.

\subsubsection{Построение бинарных выходов}

Параметр hash\_size -- количество бит в выходном бинарном дескрипторе. Мы добавили к полученной на предыдущем этапе сети еще один слой -- полносвязный слой с hash\_size нейронами и функцией активации сигмоида, этот слой называется бинаризирующим. Расположили его после слоя пакетной нормировки, но перед классифицирущим слоем. При этом классифицирующий слой заново был инициализирован и вся сеть обучалась ещё раз по предложенной выше схеме, задав в качестве начального приближения полученные на предыдущем этапе веса. Бинарный дескриптор или хеш -- результат сравнения выходов бинаризирующего слоя с 0.5, он имеет размерность hash\_size бит. Изменением этого параметра проверили хеши длиной 128, 256 и 512 бит соответственно.

Предложенный метод бинаризации повторил алгоритм сигмоиды из статьи~\cite{lin2015deep} за исключением того, что в предложенном методе в качестве базовой архитектуры нейронной сети вместо алгоритма из статьи используется модифицированный алгоритм VGG16.

\section{Экспериментальное исследование}

\subsection{Распознавание по походке}

Для экспериментальной оценки распознавания по походке выбрана коллекция данных TUM GAID~\cite{hofmann2014tum}, а также коллекция, используемая в~\cite{andersson2015person} (в дальнейшем обозначена как коллекция Kinect). Метрикой точности работы алгоритма являлся процент правильно распознанных видеопоследовательностей по метрике Rank~1 и Rank~5. Видеопоследовательность считается правильно распознанной по метрике Rank~k, если корректный класс содержится в списке $k$ наиболее вероятных классов.

Работа алгоритма на коллекции Kinect оценивали посредством кросс-валидации с разделением коллекции на 10 частей. На коллекции GAID работа оценивали по стандартной для этой коллекции схеме, описанной в~\cite{hofmann2014tum}: для каждого из 155 классов, входящих в тестовое подмножество, первые четыре примера входят в обучающую выборку, а все остальные - в тестовую.

\subsection{Распознавание по внешнему виду}

Для экспериментальной оценки распознавания по внешнему виду выбрана коллекция данных Market1501~\cite{zheng2015scalable}. Для оценки качества переноса результатов использовали коллекцию данных CUHK03~\cite{li2014deepreid}. Подробное сравнение этих коллекций приведено в таблице~\ref{datasets}.

\begin{table}[ht]
    \caption{Сравнение эталонных коллекций.}
    \label{datasets}
    \centering\medskip\tabcolsep=2pt%\small
    \begin{tabular}{ p{4cm} p{2cm} p{2cm} } 
        \hline 
        Коллекция данных & CUHK03~\cite{li2014deepreid} & Market1501~\cite{zheng2015scalable} \\
        \hline
        Число личностей & 1467 & $\mathbf{1501}$ \\
        Примеров на человека & 2-10 & $\mathbf{\approx 15}$ \\
        Размер кадров & $\approx160\times60$ & $128\times64$ \\
        Число камер & 2 & $\mathbf{6}$ \\
        \hline
    \end{tabular}
\end{table}
    
\subsubsection{Протокол тестирования}
\label{sec:protocol}

Отдельно рассмотрели два протокола тестирования, представленные на выбранной коллекции~\cite{zheng2015scalable}.

Протокол оценки качества запросов по одному изображению состоит из следующих шагов:

\begin{enumerate}
    \item Обучение алгоритма извлечения дескриптора изображения человека исключительно на обучающей выборке.
    \item Построение базы дескрипторов -- каждой картинке ставят в соответствие дескриптор с помощью тестируемого алгоритма. В тестовой выборке фотографии 750 личностей и 2 класса с объектами, не являющимися людьми. Изображения распределены по классом примерно равномерно.
    \item Построение дескрипторов-запросов для изображений из выборки запросов. Всего 3368 запросов. Картинки из выборки запросов до этого никак не используются.
    \item Расчет качества по метрикам, описанным в разделе~\ref{sec:metrics}.
\end{enumerate}

Запрос по нескольким изображениям отличается тем, что запросы состоят из набора изображений: всех изображений из query\_set, соответствующих конкретному человеку, снятому с конкретной камеры; чаще всего это 2-6 изображений. Действия проводятся такие же, за исключением пункта 3.

\begin{enumerate}
    \item[3.] Сначала для каждого изображения в запросе строят дескриптор, затем для построения дескриптора-запроса дескрипторы в наборе объединяются с помощью какого-то алгоритма -- для предложенного алгоритма считали среднее по каждому элементу.
\end{enumerate}

\subsubsection{Используемые метрики качества}
\label{sec:metrics}

Для определения качества работы алгоритма использовали метрики Rank~1 и Rank~5. Для ранжирования в этих метриках использовали расстояние между вещественными и бинарными дескрипторами по метрикам $L_2$ и $L_1$ соответсвенно. Для части реализаций использовали меру качества Mean Average Precision (mAP)~\cite{wiki:informationalretrieval}.

На выбранной эталонной коллекции данных известны реализации алгоритмов повторной идентификации. Для существующих реализаций использовали точность, описанную в оригинальных работах. Предложенное решение сравнили со следующими:

\begin{enumerate}
    \item Лучшим на данный момент подходом для этой задачи не использующим нейросети GOG~\cite{karanam2016systematic}.
    \item Лучшими на данный момент подходами для этой задачи, основанными на нейронных сетях ResNet~\cite{hermans2017defense} и MobileNet~\cite{zhang2017deep}.
\end{enumerate}

Для проверки переносимости базового алгоритма с коллекции Market1501 на коллекцию CUHK03~\cite{li2014deepreid} и обратно реализовали такой же протокол тестирования на CUHK03.

\section{Результаты}

\subsection{Распознавание по походке}

Алгоритм оценивался на двух наборах данных: на наборе, использованном в работе~\cite{andersson2015person} и на коллекции TUM GAID~\cite{hofmann2014tum}. Первый набор использовался для оценки трёхмерной версии алгоритма, а второй - для оценки двухмерной версии. Результаты представлены в таблице~\ref{experimentalresults}.

\begin{table}[ht]
    \caption{Сравнение методов распознавания по походке.}
    \label{experimentalresults}
    \centering\medskip%\tabcolsep=2pt%\small
    \begin{tabular}{ l c c } 
        \hline
         & Rank~1 & Rank~5 \\
        \hline
        Kinect~\cite{andersson2015person} & 93.9 & 100 \\
        GAID-N~\cite{hofmann2014tum} & 95.8 & 98.7 \\
        GAID-B~\cite{hofmann2014tum} & 76.5 & 93.2 \\
        GAID-S~\cite{hofmann2014tum} & 87.8 & 94.5 \\
        \hline
    \end{tabular}
\end{table}

Строка “Kinect” соответствует набору данных, используемом в~\cite{andersson2015person} и~\cite{yang2016relative}, а следующие строки соответствуют различным подмножествам тестового набора в коллекции GAID: GAID-N - обычная походка, GAID-B - видеопоследовательности, на которых на человека надет рюкзак (что заметно влияет на силуэт и походку), а GAID-S - последовательности, в которых на человека надеты бахилы. Как видно из таблицы, алгоритм показывает хорошее качество распознавания как с картой глубины, так и без неё. Из этого следует, что качество распознавания при использовании данного метода больше зависит от качества построения скелета, чем от наличия информации о глубине.

\subsection{Распознавание по внешнему виду}

Экспериментальное сравнение с лучшими реализациями на данный момент (таблицы~\ref{comparesingle},~\ref{comparemultiple}) показало, что предложенная реализация имеет сравнимую с наилучшей точность по мере качества Rank~1 в задаче повторной идентификации с запросом из одного изображения. А с запросом из нескольких изображений предложенный алгоритм справился лучше известных аналогов, что демонстрирует его применимость в обработке видеопоследовательностей, где и используется несколько изображений.

\begin{table}[ht]\small
    \caption{Сравнение методов построения вещественных дескрипторов, бинаризация не проводилась, запрос из \textbf{одного} изображения.}
    \label{comparesingle}
    \centering\medskip%\tabcolsep=2pt%\small
    \begin{tabular}{ p{2.6cm} c c c } 
        \hline 
        Алгоритм & Rank~1, \% & Rank~5, \% & mAP, \% \\
        \hline
        GOG~\cite{karanam2016systematic} & 58.6 & 79.4 & -- \\
        Предложенный метод & 85.33 & \textbf{99.55} & 51.42 \\
        ResNet+ TripletLoss~\cite{hermans2017defense} & 86.67 & 93.38 & \textbf{81.07} \\
        MobileNet+ DML~\cite{zhang2017deep} & \textbf{87.73} & -- & 68.83 \\
        \hline
    \end{tabular}
\end{table}

\begin{table}[ht]\small
    \caption{Сравнение методов построения вещественных дескрипторов, бинаризация не проводилась, запрос из \textbf{нескольких} изображений.}
    \label{comparemultiple}
    \centering\medskip%\tabcolsep=2pt%\small
    \begin{tabular}{ p{2.6cm} c c c } 
        \hline 
        Алгоритм & Rank~1, \% & Rank~5, \% & mAP, \% \\
        \hline
        ResNet+ TripletLoss~\cite{hermans2017defense} & 91.75 & 95.78 & 87.18 \\
        MobileNet+ DML~\cite{zhang2017deep} & 91.66 & -- & 77.14 \\
        Предложенный метод & \textbf{92.91} & \textbf{99.73} & \textbf{62.10} \\
        \hline
    \end{tabular}
\end{table}

Экспериментальная проверка (таблица~\ref{comparebinarization}) показала, что наилучшим решением для дескриптора длиной 512 бит является алгоритм DBE, но наивный подход ненамного ему уступает. При уменьшении дескриптора наилучший результат показывает метод сигмоиды.

\begin{table}[ht]\small
    \caption{Сравнение методов бинаризации. Изображена точность Rank~1, больше -- лучше.}
    \label{comparebinarization}
    \centering\medskip%\tabcolsep=2pt%\small
    \begin{tabular}{ p{2.8cm} c c c } 
        \hline 
        Алгоритм & 512 бит & 256 бит & 128 бит \\
        \hline
        Наивная бинаризация & 83.72 & -- & -- \\
        Выделение главных компонент~\cite{halko2011finding} & 78.50 & 75.15 & 68.34 \\
        Случайный лес~\cite{breiman2001random} & 83.72 & 77.46 & 65.17 \\
        Алгоритм DBE~\cite{liu2017end} & \textbf{83.90} & 78.50 & 71.79 \\
        Предложенный метод & 83.40 & \textbf{79.15} & \textbf{75.20} \\
        \hline
    \end{tabular}
\end{table}

Проведенная экспериментальная оценка (рис.~\ref{comparetransit}) показала, что алгоритм, подготовленный на данных из Market1501, применим на других полученных из независимого источника данных. Точность Rank~1 уменьшилась менее, чем на 1\%. Однако алгоритм, подготовленный на данных из CUHK03 теряет в точности при переходе на Market1501, что показывает, что эталонная коллекция CUHK03 недостаточно разнообразна, на ней происходит переобучение.

\begin{figure}[ht]
    \begin{tikzpicture}
        \selectcolormodel{gray}
        \begin{axis}[
            ybar, axis on top,
            height=5cm,width=0.96\linewidth,
            bar width=0.6cm,
            ymajorgrids,
            major grid style={draw=white},
            enlarge y limits={value=.1,upper},
            ymin=0, ymax=100, ytick={0,20,40,60,80,100},
            axis x line*=bottom,
            y axis line style={opacity=0},
            tickwidth=0pt,
            enlarge x limits=true,
            legend style={
                at={(0.5,-0.2)},
                anchor=north,
                legend columns=-1,
                /tikz/every even column/.append style={column sep=0.5cm}
            },
            ylabel={Rank~1, \%},
            symbolic x coords={
                Market,
                Market/CUHK,
                CUHK,
                CUHK/Market},
            xtick=data,
            nodes near coords={
                \pgfmathprintnumber[precision=1]{\pgfplotspointmeta}
            }
        ]
        \addplot[black, fill=lightgray]
        	coordinates {
            	(Market,85.33)
            	(Market/CUHK,84.91)
            	(CUHK,92.67)
            	(CUHK/Market,57.92)
            };
        \addplot[black, fill=darkgray]
        	coordinates {
        	    (Market,83.72)
        	    (Market/CUHK,80.45) 
        		(CUHK,89.94)
        		(CUHK/Market,48.30)
        	};
        \legend{Вещественный,Бинарный}
        \end{axis}
    \end{tikzpicture}
    \caption{Оценка возможности переноса на другие независимые данные.}
    \label{comparetransit}
\end{figure}

Нужно заметить, изображения в разных эталонных коллекциях имеют различное разрешение, а люди на них занимают разный процент кадра. Вопрос зависимости качества обучения от этих дополнительных параметров эталонной коллекции требует дополнительного исследования в будущем. На данный момент он не может быть решен ввиду малого количества коллекций достаточного для обучения нейросетевых алгоритмов размера.

\section{Заключение}

В работе предлагается два взаимодополняющих метода повторной идентификации человека: по внешности и по походке.

Алгоритм распознавания человека по походке, основанный на работе~\cite{yang2016relative} использует три типа признаков для классификации: антропометрические признаки, признаки относительных расстояний и признаки движения. Была произведена оценка алгоритма на двух наборах данных, и он показал хорошее качество распознавание как с использованием дополнительной информации из карты глубины, так и без неё.

Алгоритм распознавания человека по внешности справился с задачей поиска по нескольким изображениям справился лучше аналогов по мере качества Rank~1, Rank~5 и mAP на эталонной коллекции Market1501. Бинарная модификация уступила базовому алгоритму по точности (83.90\% против 85.33\% по метрике Rank~1), но полученные дескрипторы занимают на 1-2 порядка меньше памяти. Проверка переносимости показала, что предложенный алгоритм можно использовать на данных, полученных из независимого источника.

\section{Благодарности}

Проект выполнен при частичной поддержке гранта РФФИ №16-29-09612 офи-м "Исследование и разработка методов биометрической идентификации человека по походке, жестам и комплекции в данных видеонаблюдения"

\bibliographystyle{unsrt}
\addcontentsline{toc}{section}{\bibname}	% Добавляем список литературы в оглавление
\bibliography{bibliography}						% Подключаем BibTeX-базы


\section{English translation}

Human recognition by gait and visual features

Arseev S. P., Konushin A.S., Liutov V. S.

Lomonosov Moscow State University

NRU Higher School of Economics

9413serg@gmail.com

anton.konushin@graphics.cs.msu.ru

vladimir.lutov@graphics.cs.msu.ru -- +79166622623 (для связи)

biometrics, gait recognition, gait, visual, anthropometric, relative distance, motion features, person reidentification, deep binary hash, 

This work focused on person identification task in video-sequence. For this task proposed two complementing solution, which can be applied in different cases: gait and visual recognition. For gait recognition three kinds of features are used: anthropometric features, based on the length of the skeleton segments; relative distance features, based on relative distances between the skeleton joints; and motion features, based on the movement of a joint between two frames. Two versions of the gait recognition algorithm are presented: the first one uses the depth data alongside with the images while the other one uses only the video seqience. For visual recognition proposed deep learning algorithm, that returns binary image features. Each algorithm were tested on two dataset. Furthermore, described testing protocol transfer from one dataset to another dataset to check trained model transferability.

\end{document}
