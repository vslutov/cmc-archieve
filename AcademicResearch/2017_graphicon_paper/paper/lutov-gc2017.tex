\documentclass[a4paper]{article}
\usepackage{gc2017ru}
\graphicspath{{images/}}

\usepackage{pgfplots}
\usepackage{epstopdf}
\usepackage{hyperref}
\pgfplotsset{compat=1.14}

%%% Информация о статье на русском языке %%%

\title{Глубинные двоичные дескрипторы изображения человека для его повторной идентификации и сопровождения в видео}

\author{В. С. Лютов$^1$, А. С. Конушин$^{1,2}$}

\email{vladimir.lutov@graphics.cs.msu.ru|anton.konushin@graphics.cs.msu.ru}

\organization{$^1$МГУ, Москва, Россия;\par $^2$ВШЭ, Москва, Россия}

\abstract{В работе рассматривается задача повторной идентификации человека -- определения личности неизвестного по фотографии с камеры видеонаблюдения. В работе предлагается базовый метод, основанный на модификации нейросетевого алгоритма классификации VGG16. Экспериментальное сравнение алгоритма продемонстрировало большую точность в сравнении с аналогами. Также предлагается модификация алгоритма, строящая бинарные дескрипторы изображения сравнимой точности с исходным дескриптором.}

\keywords{компьютерное зрение, повторная идентификация, глубинное обучение}

\authorsInfo
{
    Конушин Антон Сергеевич, д.ф.-м.н., профессор кафедры автоматизации систем вычислительных комплексов факультета вычислительной математики и кибернетики Московского государственного университета. Его e-mail anton.konushin@graphics.cs.msu.ru.

    Лютов Владимир Сергеевич, студент кафедры автоматизации систем вычислительных комплексов факультета вычислительной математики и кибернетики Московского государственного университета. Его e-mail vladimir.lutov@graphics.cs.msu.ru.
}

%%% Информация о статье на английском языке %%%

\titleEng{Human image deep binary descriptor for person reidentification and tracking in video}

\authorEng{V. S. Liutov$^1$, A. S. Konushin$^{1,2}$}

\organizationEng{$^1$MSU, Moscow, Russia;\par $^2$HSE, Moscow, Russia}

\abstractEng{The work focuses on human reidentification, i.e. identifying an unknown person using a photo from a surveillance camera. A base method that involves modifying the VGG16 neural network algorithm is proposed. Experimental comparison of the algorithm proved to be highly accurate compared to similar approaches. Furthermore, an algorithm modification, which creates binary visual descriptors that have comparable accuracy with the original descriptor, is presented.}

\keywordsEng{computer vision, reidentification, deep learning}


\begin{document}

\maketitle

\begin{multicols*}{2}

\section{Введение}

В работе рассматривается задача построения дескрипторов изображения человека для повторной идентификации и сопровождения. Повторная идентификация - автоматическое сопоставление обнаружений людей с их личностями. Иначе говоря, требуется определить, видели ли мы раньше обнаруженного человека, и, если видели, то где и когда именно.

Например, в сценариях видеонаблюдения, решение этой задачи позволит выяснить откуда пришел, куда ушел и с кем общался участник некоторого инцидента. Данная задача является актуальной задачей компьютерного зрения, так как для работы в реальных условиях требуется высокая скорость поиска изображений и высокая переносимость алгоритма, подготовленного на одних данных на данные, полученные из независимого источника.

Быстрая повторная идентификация в первую очередь может использоваться в сопровождении, для дальнейшего повышения качества ассоциации фрагментов траекторий одного и того же человека, например, когда человек в промежутке между этими фрагментами был скрыт каким-то элементом сцены\cite{tracking}.

На вход алгоритму повторной идентификации подается результат работы алгоритма обнаружения людей -- обнаружения. Обнаружения -- выделенные из полученных со статических камер изображений прямоугольники, содержащие изображения людей. Требуется определить, как обнаружения соотносятся с личностями людей.

Эта задача является частным случаем задачи идентификации человека. Она традиционно решается за два этапа: построение дескриптора изображения человека и поиск по базе дескрипторов\cite{review1}. Пример работы приведен на рисунке \ref{rankexample}. В данной работе предлагается решать подзадачу построения дескриптора.

\begin{figure}[H]
    \centering{\includegraphics[width=\linewidth]{lutov-image2.eps}}
    \caption{Пример работы предложенного алгоритма. Чем левее изображения-кандидаты, тем ближе их дескрипторы к дескриптору-запросу. Зеленым отмечены верные изображения, красным - неверные.}
    \label{rankexample}
\end{figure}

\section{Обзор существующих методов}

Построение бинарного дескриптора состоит из двух этапов: сначала строится вещественный дескриптор достаточно высокого качества, затем на основе алгоритма построения вещественного дескриптора строится бинарный дескриптор.

\subsection{Вещественные}

Методы построения вещественных дескрипторов можно разбить на три множества:

\begin{enumerate}
    \item \textbf{Методы без машинного обучения} не используют информацию о том, какие изображения находятся в коллекции изображений и работают для всех изображений одинаково. Исследования\cite{review1}\cite{review2} показывают, что чем больше мы принимаем во внимание коллекцию изображений, с которой работаем, тем большую точность работы получаем.
    
    \item \textbf{Методы с машинным неглубинным обучением} используют информацию о том, какие изображения находятся в коллекции изображений. Чаще всего они представляют собой комбинацию классических методов обработки изображений и методов машинного обучения, также они используют математическую статистику. По результатам обзора\cite{review1} метод “Иерархический гауссовый дескриптор для повторной идентификации человека” GOG\cite{gog} показывает наилучшую точность в данном классе.
    
    \item \textbf{Методы с глубинным обучением} показывают наилучшие результаты для этой задачи\cite{resnet}\cite{dml}. Данные методы широко применяются в различных задачах компьютерного зрения и показывают все лучшие результаты, например в задаче выделения движущихся объектов со статичной камеры видеонаблюдения\cite{backgroundsubstraction}.
    
\end{enumerate}

Нейросетевые методы повторной идентификации весьма популярны. На данный момент изучаются как независимые методы повторной идентификации \cite{cnn4reid}, так и комплексные подходы, использующие решение смежных задач, таких как анализ цвета одежды человека \cite{closes} или поиск изображения по его текстовому описанию \cite{findtext}.

\subsection{Бинарные}

В данной работе акцентируется внимание на построении бинарных дескрипторов произвольной длины. В работах, посвященных повторной идентификации, подобные исследования ранее не проводились.

Однако, в других работах по компьютерному зрению подобные методы рассматривались. Построение бинарных дескрипторов (хешей) небольшой размерности можно сделать разными способами. В ходе этой работы были экспериментально проверены следующие частные методы:

\begin{enumerate}
    \item Наивная бинаризация - поэлементное сравнение исходного дескриптора с 0. Значениям больше 0 соответсвует 1, остальным -- 0.
    \item Выделение наиболее значимых элементов исходного дескриптора с помощью метода машинного обучения. Например, с помощью алгоритма "random forest" \cite{randomforests}.
    \item Преобразование в пространство меньшей размерности с помощью метода главных компонент\cite{pca}, затем бинаризация.
    \item Нейросетевые методы построения бинарных дескрипторов. Были проверены два таких алгоритма: алгоритм сигмоиды\cite{deephash} и его модификация DBE\cite{dbe}.
\end{enumerate}

Алгоритм сигмоиды заключается в добавлении к сети, строящей вещественные дескрипторы, полносвязного слоя с сигмоидальной функцией активации.

В алгоритме DBE вместо этого слоя используется последовательность из нескольких слоев:

$$f_{DBE}(X) = tanh(ReLU(BN(X W_{DBE}+b_{DBE}))),$$

\begin{expl}
    \where где $f_{DBE}$ -- алгоритм DBE, $X$ -- вещественный дескриптор, $tanh(Z)$ -- поэлементный гиперболический тангенс, $ReLU(Z)$ -- поэлементный $max(0, z_i)$, $BN$ -- слой "batch normalization"\cite{batchnormalization}, $W_{DBE}, b_{DBE}$ -- оптимизируемые веса алгоритма, матрица и вектор, соответственно.
\end{expl}

\section{Предложенный метод}

По результатам проведенного обзора в качестве базового алгоритма был выбран алгоритм VGG16, предобученный на задаче ImageNet. Он состоит из 5ти блоков сверток+max-pooling и 3 полносвязных слоев. На вход он получает изображение размером 224x224x3, на выходе -- вероятность принадлежности каждой из картинок к тому или иному классу из 1000 классов. Предложенная модификация изображена на рисунке \ref{architecture} и подробно описана ниже. Исходный код доступен по ссылке \url{https://github.com/vslutov/reidentification}.

\begin{figure}[H]
    \centering{\includegraphics[height=\linewidth, angle=90]{lutov-image3.eps}}
    \caption{Схема предложенного алгоритма.}
    \label{architecture}
\end{figure}

\subsection {Предобработка данных}

Случайным образом разделим тренировочные данные на обучающую и валидационную выборки. Отношение количества примеров в обучающей и валидационной выборке равно 9/1. В процессе обучения нейросеть будет видеть только обучающую выборку, а на валидационной выборке мы будем проверять насколько хорошо она обучилась.

Во время обучения цвета на картинках нормализовались -- каждый канал каждого пикселя приводился линейным преобразованием к такому виду, чтобы выборочное мат. ожидание каждого отдельного канала отдельного пикселя по всей выборке было равно нулю, а выборочная дисперсия -- единице. Однако в оригинальной нейросетевой моделе VGG16, обученной на ImageNet\cite{vgg}, предобученные веса были получены на картинках с другой предобработкой. В работе\cite{vgg} использовалось вычитание среднего RGB значения по каждому пикселю по обучающей выборке, иначе говоря приведение выборочного мат. ожидания к нулю. Необходимо отметить, что предполагается использовать предложенный алгоритм для потоковой обработки видео с камер видеонаблюдения. В разное время суток кадры такого видео имеют разный уровень яркости и контрастности. Нормализация выборочных мат. ожидания и дисперсии в рамках небольшой выборки позволяет сгладить данное различие.

После нормализации картинки горизонтально зеркально отражались с вероятностью $\frac{1}{2}$ и поворачивались на случайный угол до 20 градусов.

\subsection{Адаптация под задачу повторной идентификации человека}

Так как мы собираемся обрабатывать изображения людей, изображения будут вертикально вытянуты. Предобученные на ImageNet полносвязные слои пригодны только для картинок фиксированного размера (как в ImageNet, 224x224x3), поэтому использовать их в данной задаче нецелесообразно и придется их убрать. Сверточные слои оставим без изменений.

Также в ходе экспериментального тестирования выяснилось, что при удалении самого глубокого блока сверток и max-pooling слоя точность алгоритма увеличивается. Это связано с тем, что в данной задаче для алгоритма важнее низкоуровневые свойства такие как цвет и текстура одежды.

Добавляем в конец сети GlobalAveragePooling слой. Это самый простой способ получить низкоуровневое представление информации о картинке.

Добавляем в конец сети слой "batch normalization"\cite{batchnormalization}. Этот слой делает предсказуемым распределение каждого элемента в дескрипторе -- мат. ожидание равно 0, дисперсия 1. Эта модификация увеличивает точность работы алгоритма и позволит нам сделать наивную бинаризацию простым сравнением с нулем, длина хеша при такой бинаризации равна числу выходов слоя "batch normalization" -- 512.

Добавим в конец сети один полносвязный слой с функцией активации softmax и количеством нейронов равному числу классов в обучающей выборке -- для Market1501\cite{market1501} это 751. Назовем этот слой классифицирующим, он используется только во время обучения. Во время обучения в качестве функции ошибки у нас будет выступать ошибка идентификации -- многоклассовая перекрестная энтропия выходов классифицирующего слоя и ожидаемого результата. Вещественный дескриптор -- выход слоя "batch normalization", он имеет размерность 512 вещественных чисел.

\subsection{Обучение нейронной сети}

Используем оптимизатор nadam\cite{nadam}. Размер батча -- 128 изображений. Если в течение 4х эпох ошибка на валидационной выборке не уменьшается, то уменьшим скорость обучения в 10 раз. Если в течение 10 эпох ошибка на валидационном наборе не уменьшается, то мы достигли локального минимума, остановим обучение.

\begin{enumerate}
    \item Отключаем обучение всех слоев, кроме последнего полносвязного.  Обучаем 50 эпох на обучающей выборке. 
    \item Включаем обучение всех сверточных слоев. Еще раз проводим 50 эпох обучения на обучающей выборке. Дескриптор -- выходы предпоследнего слоя (нормализации по батчу).
\end{enumerate}

Этот метод обучения показал точность rank-1 85\%, что сравнимо с наилучшими из известных методов решения этой задачи. Из чего можно сделать вывод, что в этой задаче низкоуровневые признаки сохраняют основную необходимую информацию и дальнейшее усложнение архитектуры нецелесообразно.

\subsection{Построение бинарных выходов}

Введем параметр hash\_size -- количество бит в выходном бинарном дескрипторе. Добавим к полученной на предыдущем этапе сети еще один слой -- полносвязный слой с hash\_size нейронами и функцией активации сигмоида, назовем этот слой бинаризирующим. Расположим его после слоя "batch normalization", но перед классифицирущим слоем. При этом классифицирующий слой требуется заново инициализировать и обучить всю сеть еще раз по предложенной выше схеме, задав в качестве начального приближения полученные на предыдущем этапе веса. Бинарный дескриптор или хеш -- результат сравнения выходов бинаризирующего слоя с 0.5, он имеет размерность hash\_size бит. Путем изменения этого параметра в данной работе проверены хеши длиной 128, 256 и 512 бит соответственно.

Предложенный метод бинаризации повторяет алгоритм сигмоиды из статьи \cite{deephash} за исключением того, что в предложенном методе в качестве базовой архитектуры нейронной сети вместо алгоритма из статьи используется модифицированный алгоритм VGG16.

\section{Экспериментальное исследование}

\begin{table}[H]\footnotesize
    \caption{Сравнение эталонных коллекций.}
    \label{datasets}
    \centering\medskip\tabcolsep=2pt%\small
    \begin{tabular}{ p{2.5cm} p{1cm} p{1cm} p{1.4cm} p{1.4cm} } 
        \hline 
        Коллекция данных & VIPeR\cite{viper} & PRID\cite{prid} & CUHK 03\cite{cuhk03} & Market 1501\cite{market1501} \\
        \hline
        Число личностей & 632 & 385 & 1467 & $\mathbf{1501}$ \\
        Примеров на человека & 1 & 1 & 2-10 & $\mathbf{\approx 15}$ \\
        Размер кадров & $128\times48$ & $128\times64$ & $\approx160\times60$ & $128\times64$ \\
        Число камер & 2 & 2 & 2 & $\mathbf{6}$ \\
        \hline
    \end{tabular}
\end{table}

Был проведен обзор открытых коллекций по результатам которого составлена таблица \ref{datasets}.

Для экспериментальной оценки выбрана коллекция данных Market1501, состоящая из 1501 набора изображений людей. Изображения цветные и имеют разрешение 128x64, они разделены на 3 непересекающихся множества:

\begin{enumerate}
    \item Обучающая выборка, состоящая из 12936 изображений 751 человека. Для каждого изображения есть метка, какой человек на нем изображен.
    \item Тестовая выборка, состоящая из 19732 изображений 750 человек и два класса отвлекающих изображений. Все фотографии подписаны. Личности в обучающей и тестовой выборке не пересекаются.
    \item Выборка запросов, состоящая из 3368 изображений 750 человек. Здесь находятся другие фотографии тех же личностей, что и в тестовой выборке. Фотографии подписаны.
\end{enumerate}
    
\subsection{Протокол тестирования}

Рассмотрим два протокола тестирования, представленные на выбранной коллекции: запрос по \textbf{одному} и \textbf{нескольким} изображениям.

Запрос по \textbf{одному} изображению:

\begin{enumerate}
    \item Обучаем алгоритм извлечения дескриптора изображения человека исключительно на обучающей выборке.
    \item Строим базу дескрипторов -- каждой картинке ставим в соответствие дескриптор с помощью тестируемого алгоритма. В тестовой выборке фотографии 750 личностей и 2 класса с объектами, не являющимися людьми. Изображения распределены по классом примерно равномерно.
    \item Берем изображения-запросы из выборки запросов, для них строим дескрипторы-запросы. Всего 3368 запросов. Картинки из выборки запросов до этого никак не использовались.
    \item Для каждого дескриптора-запроса находим k ближайших соседей среди дескрипторов из базы дескрипторов, отсортированных по близости (по метрике L2).
    \item Определяем классы этих дескрипторов.
\end{enumerate}

Запрос по \textbf{нескольким} изображениям отличается тем, что запросы состоят из набора изображений. Эти наборы состоят из всех изображений из query\_set, соответствующих конкретному человеку, снятому с конкретной камеры, чаще всего это 2-6 изображений. Действия проводятся такие же, за исключением пункта 3.

\begin{enumerate}
    \item[3.] Сначала для каждого изображения в запросе строится дескриптор, затем для построения дескриптора-запроса дескрипторы в наборе объединяются с помощью какого-то алгоритма -- чаще всего для каждого элемента считается среднее или максимум, но возможны более сложные алгоритмы.
\end{enumerate}

Для предложенного алгоритма в данной работе считалось среднее по каждому элементу.

\subsection{Используемые метрики качества}

Для определения похожести изображений использовалось сравнение вещественных и бинарных дескрипторов по метрикам $L_2$ и $L_1$ соответсвенно.

$rank-k$ -- процент запросов из выборки запросов, для которых изображение нужного класса содержится среди первых k примеров, отсортированных по похожести. 

Также в этой эталонной коллекции для большинства реализаций используется мера точности Mean Average Precision (mAP) \cite{map}.

На выбранной эталонной коллекции данных уже сделано несколько реализаций алгоритмов повторной идентификации. Предложенное решение сравним с следующими реализациями:

\begin{enumerate}
    \item Лучшим на данный момент подходом для этой задачи не использующим нейросети GOG\cite{review1}.
    \item Лучшими на данный момент подходами для этой задачи, основанными на нейронных сетях ResNet\cite{resnet} и MobileNet\cite{dml}.
\end{enumerate}

Для существующих реализаций мы будем использовать точность, описанную в оригинальных работах, а реализацию предложенного алгоритма протестируем по протоколу, описанному в обзоре существующих методов. Отметим, что авторы статьи \cite{review1} не проводили тестирования алгоритма GOG на запросах, состоящих из нескольких изображений, поэтому результаты для этого протокола не добавлены в соответствующую таблицу, однако сравнительно низкая точность на запросах из одного изображения, позволяет предположить, что он уступает нейросетевым алгоритмам построения дескрипторов изображения человека.
В качестве меры точности будем использовать метрики mAP и rank-1, rank-5.
Для проверки методов бинаризации и сравнения качества бинаризации при разных размерах бинарного дескриптора мы будем использовать тот же тестовый протокол, но будем использовать только основную меру качества для данной эталонной коллекции -- rank-1.

Для проверки переносимости базового алгоритма с коллекции Market1501 на коллекцию CUHK03\cite{cuhk03} и обратно был реализован такой же протокол тестирования на CUHK03. Все личности были случайным образом разбиты на два непересекающихся множества — тренировочный и тестовые наборы, затем из тестового набора были выделены случайные 15\% изображений в качестве множества запросов, эти изображения больше не присутствуют в тестовом наборе. Именно такое отношение изображений-запросов ко всем изображениям для тестирования используется в Market1501.

\section{Результаты}

\begin{table}[H]\small
    \caption{Сравнение методов построения вещественных дескрипторов, бинаризация не проводилась, запрос из \textbf{одного} изображения.}
    \label{comparesingle}
    \centering\medskip%\tabcolsep=2pt%\small
    \begin{tabular}{ p{2.3cm} c c c } 
        \hline 
        Алгоритм & rank-1, \% & rank-5, \% & mAP, \% \\
        \hline
        GOG \cite{review1} & 58.6 & 79.4 & -- \\
        Предложенный метод & 85.33 & \textbf{99.55} & 51.42 \\
        ResNet+ TripletLoss \cite{resnet} & 86.67 & 93.38 & \textbf{81.07} \\
        MobileNet+ DML \cite{dml} & \textbf{87.73} & -- & 68.83 \\
        \hline
    \end{tabular}
\end{table}

\begin{table}[H]\small
    \caption{Сравнение методов построения вещественных дескрипторов, бинаризация не проводилась, запрос из \textbf{нескольких} изображений.}
    \label{comparemultiple}
    \centering\medskip%\tabcolsep=2pt%\small
    \begin{tabular}{ p{2.3cm} c c c } 
        \hline 
        Алгоритм & rank-1, \% & rank-5, \% & mAP, \% \\
        \hline
        ResNet+ TripletLoss\cite{resnet} & 91.75 & 95.78 & 87.18 \\
        MobileNet+ DML\cite{dml} & 91.66 & -- & 77.14 \\
        Предложенный метод & \textbf{92.91} & \textbf{99.73} & \textbf{62.10} \\
        \hline
    \end{tabular}
\end{table}

Экспериментальное сравнение с лучшими реализациями на данный момент (таблицы \ref{comparesingle} и \ref{comparemultiple}) показало, что предложенная реализация имеет сравнимую с наилучшей точность по мере качества rank-1 в задаче повторной идентификации с запросом из одного изображения. А с запросом из нескольких изображений предложенный алгоритм справился лучше известных аналогов, что демонстрирует его применимость в обработке видеопоследовательностей, где и используется несколько изображений.

\begin{table}[H]\small
    \caption{Сравнение методов бинаризации. Изображена точность rank-1, больше -- лучше.}
    \label{comparebinarization}
    \centering\medskip%\tabcolsep=2pt%\small
    \begin{tabular}{ p{2.8cm} c c c } 
        \hline 
        Алгоритм & 512 бит & 256 бит & 128 бит \\
        \hline
        Наивная бинаризация & 83.72 & -- & -- \\
        Выделение главных компонент\cite{pca} & 78.50 & 75.15 & 68.34 \\
        "Random forest"\cite{randomforests} & 83.72 & 77.46 & 65.17 \\
        Алгоритм DBE\cite{dbe} & \textbf{83.90} & 78.50 & 71.79 \\
        Предложенный метод & 83.40 & \textbf{79.15} & \textbf{75.20} \\
        \hline
    \end{tabular}
\end{table}

Экспериментальная проверка (таблица \ref{comparebinarization}) показала, что наилучшим решением для дескриптора длиной 512 бит является алгоритм DBE, но наивный подход ненамного ему уступает. При уменьшении дескриптора наилучший результат показывает метод сигмоиды.

\begin{figure}[H]
    \begin{tikzpicture}
        \begin{axis}[
            ybar, axis on top,
            height=5cm,width=0.96\linewidth,
            bar width=0.6cm,
            ymajorgrids,
            major grid style={draw=white},
            enlarge y limits={value=.1,upper},
            ymin=0, ymax=100, ytick={0,20,40,60,80,100},
            axis x line*=bottom,
            y axis line style={opacity=0},
            tickwidth=0pt,
            enlarge x limits=true,
            legend style={
                at={(0.5,-0.2)},
                anchor=north,
                legend columns=-1,
                /tikz/every even column/.append style={column sep=0.5cm}
            },
            ylabel={rank-1, \%},
            symbolic x coords={
                Market,
                Market/CUHK,
                CUHK,
                CUHK/Market},
            xtick=data,
            nodes near coords={
                \pgfmathprintnumber[precision=1]{\pgfplotspointmeta}
            }
        ]
        \addplot 
        	coordinates {
            	(Market,85.33)
            	(Market/CUHK,84.91)
            	(CUHK,92.67)
            	(CUHK/Market,57.92)
            };
        \addplot 
        	coordinates {
        	    (Market,83.72)
        	    (Market/CUHK,80.45) 
        		(CUHK,89.94)
        		(CUHK/Market,48.30)
        	};
        \legend{Вещественный,Бинарный}
        \end{axis}
    \end{tikzpicture}
    \caption{Оценка возможности переноса на другие независимые данные}
    \label{comparetransit}
\end{figure}

Проведенная экспериментальная оценка (рис. \ref{comparetransit}) показала, что алгоритм, подготовленный на данных из Market1501, применим на других полученных из независимого источника данных. Точность rank-1 уменьшилась менее, чем на 1\%. Однако алгоритм, подготовленный на данных из CUHK03 теряет в точности при переходе на Market1501, что показывает, что эталонная коллекция CUHK03 недостаточно разнообразна, на ней происходит переобучение.

Нужно заметить, изображения в разных эталонных коллекциях имеют различное разрешение, а люди на них занимают разный процент кадра. Вопрос зависимости качества обучения от этих дополнительных параметров эталонной коллекции требует дополнительного исследования в будущем. На данный момент он не может быть решен ввиду малого количества коллекций достаточного для обучения нейросетевых алгоритмов размера.

\section{Заключение}

В работе предложен алгоритм построения дескриптора изображения человека для повторной идентификации и сопровождения в видео. С задачей поиска по нескольким изображениям он справился лучше аналогов по мере качества rank-1, rank-5 и mAP на эталонной коллекции Market1501.

Бинарная модификация уступила базовому алгоритму по точности (83.90\% против 85.33\% по метрике rank-1), но полученные дескрипторы занимают на 1-2 порядка меньше памяти. Проверка переносимости показала, что предложенный алгоритм можно использовать на данных, полученных из независимого источника.

\section{Дальнейшие исследования}

С помощью разветвленных нейросетевых архитектур можно добиться совместной обработки разноуровневых признаков, что может привести к росту качества получаемого дескриптора.

Было бы интересно переработать тестовый протокол, чтобы увидеть результаты работы предложенного алгоритма и конкурентов для случая, когда 750 людей из тестовой выборки представлены каждый всего одной или двумя фотографиями. Эта задача возникает, если нужно сравнить кадр с видеокамеры с одной-двумя фотографиями преступников.

\begin{thebibliography}{1}
  \bibitem{randomforests} Breiman L. Random Forests // Machine learning. -- 2001. -- Т. 45. -- №. 1. -- С. 5-32.
  \bibitem{nadam} Dozat T. Incorporating Nesterov momentum into Adam. -- 2015. -- \url{http://cs229.stanford.edu/proj2015/054report.pdf}, 2015.
  \bibitem{viper} Gray D., Brennan S., Tao H. Evaluating appearance models for recognition, reacquisition, and tracking // Proc. IEEE International Workshop on Performance Evaluation for Tracking and Surveillance (PETS). – 2007. -- Т. 3. -- №. 5.
  \bibitem{pca} Halko N., Martinsson P. G., Tropp J. A. Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions // SIAM review. -- 2011. -- Т. 53. -- №. 2. -- С. 217-288.
  \bibitem{resnet} Hermans A., Beyer L., Leibe B. In Defense of the Triplet Loss for Person Re-Identification // arXiv preprint arXiv:1703.07737. -- 2017.
  \bibitem{prid} Hirzer M. et al. Person re-identification by descriptive and discriminative classification // Scandinavian conference on Image analysis. -- Springer Berlin Heidelberg, 2011. -- С. 91-102.
  \bibitem{batchnormalization} Ioffe S., Szegedy C. Batch normalization: Accelerating deep network training by reducing internal covariate shift // International Conference on Machine Learning. -- 2015. -- С. 448-456.
  \bibitem{review1} Karanam S. et al. A Systematic Evaluation and Benchmark for Person Re-Identification: Features, Metrics, and Datasets // arXiv preprint arXiv:1605.09653. – 2016.
  \bibitem{tracking} Kuplyakov D., Shalnov E., Konushin A. Further Improvement on an MCMC-based Video Tracking Algorithm. // ГРАФИКОН'2016 Труды 26-й Международной научной конференции. 2016. С. 440-444.
  \bibitem{findtext} Li S. et al. Person search with natural language description //arXiv preprint arXiv:1702.05729. -- 2017.
  \bibitem{cuhk03} Li W. et al. Deepreid: Deep filter pairing neural network for person re-identification // Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. -- 2014. -- С. 152-159.
  \bibitem{deephash} Lin K. et al. Deep learning of binary hash codes for fast image retrieval // Proceedings of the IEEE conference on computer vision and pattern recognition workshops. -- 2015. -- С. 27-35.
  \bibitem{dbe} Liu L. et al. End-to-end Binary Representation Learning via Direct Binary Embedding // arXiv preprint arXiv:1703.04960. -- 2017.
  \bibitem{gog} Matsukawa T. et al. Hierarchical gaussian descriptor for person re-identification // Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. – 2016. – С. 1363-1372.
  \bibitem{backgroundsubstraction} Morozov F., Konushin A. Background subtraction using a convolutional neural network. // ГРАФИКОН'2016 Труды 26-й Международной научной конференции. 2016. С. 445-447.
  \bibitem{map} Sepreece S. et al. Information retrieval -- 2017. -- \url{https://en.wikipedia.org/wiki/Information\_retrieval}.
  \bibitem{vgg} Simonyan K., Zisserman A. Very deep convolutional networks for large-scale image recognition // arXiv preprint arXiv:1409.1556. -- 2014.
  \bibitem{cnn4reid} Ulu A., Ekenel H. K. Convolutional neural network-based representation for person re-identification //Signal Processing and Communication Application Conference (SIU), 2016 24th. -- IEEE, 2016. -- С. 945-948.
  \bibitem{dml} Zhang Y. et al. Deep Mutual Learning // arXiv preprint arXiv:1706.00384. – 2017.
  \bibitem{market1501} Zheng L. et al. Scalable person re-identification: A benchmark // Proceedings of the IEEE International Conference on Computer Vision. -- 2015. -- С. 1116-1124.
  \bibitem{review2} Zheng L., Yang Y., Hauptmann A. G. Person Re-identification: Past, Present and Future // arXiv preprint arXiv:1610.02984. – 2016.
  \bibitem{closes} Cheng Z., Li X., Loy C. C. Pedestrian Color Naming via Convolutional Neural Network //Asian Conference on Computer Vision. -- Springer, Cham, 2016. -- С. 35-51.
\end{thebibliography}

% \aboutAuthors

\end{multicols*}

\end{document}
