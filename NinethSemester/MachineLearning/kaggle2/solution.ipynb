{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import tqdm\n",
    "import h5py\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "\n",
    "from backtester import calc_score, apply_on_test, test_generator, make_submission\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reduce dataset, we left only relevant currency\n",
    "RELEVANT_CURRENCY = 'BTC'\n",
    "\n",
    "TICKS_IN_FIVE_MINUTES = 5 * 60 // 10\n",
    "# Horizon of the forecast. This parameter is not recommended to change\n",
    "PREDICT_DELAY_TICKS = 30\n",
    "# GAP determines the sampling frequency of objects in the training set. \n",
    "# To reduce the required memory, this parameter can be increased\n",
    "GAP = 2\n",
    "\n",
    "DIVIDER = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this cell primary feature selection (relevant_columns)\n",
    "\n",
    "RELEVANT_COLUMNS = []\n",
    "f1 = h5py.File('data/part1.hdf5', 'r')\n",
    "header = f1[\"header\"][:]\n",
    "s = set()\n",
    "for exch, symbol, side, candles in utils.candles_loop(f1[\"body\"]):\n",
    "    for name in header:\n",
    "        s.add(symbol)\n",
    "        if RELEVANT_CURRENCY in symbol and name in [\"max_price\", \"amount\"]:\n",
    "            column = exch + \"/\" + symbol + \"/\" + side + \"/\" + name\n",
    "            print(column)\n",
    "            RELEVANT_COLUMNS.append(column)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(fname):\n",
    "    f = h5py.File(fname, 'r')\n",
    "    header = f[\"header\"][:]\n",
    "    loaded = []\n",
    "    columns = []\n",
    "    for exch, symbol, side, candles in utils.candles_loop(f[\"body\"]):\n",
    "        # To reduce dataset, select only relevant columns\n",
    "        for feature_num, name in enumerate(header):\n",
    "            column = exch + \"/\" + symbol + \"/\" + side + \"/\" + name\n",
    "            if column in RELEVANT_COLUMNS:\n",
    "                loaded.append(candles[:, feature_num])\n",
    "                columns.append(column)\n",
    "\n",
    "    loaded = pd.DataFrame(np.column_stack(loaded), columns=columns)\n",
    "    f.close()\n",
    "    \n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.concat((load_dataset('data/part1.hdf5'), load_dataset('data/part2.hdf5')))\n",
    "val_dataset = load_dataset('data/part3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(loaded):\n",
    "    X = []\n",
    "    y = []\n",
    "    target = loaded.loc[:, utils.TARGET_COLUMNS].values\n",
    "    \n",
    "    vals = loaded.values\n",
    "    \n",
    "    X_diff = vals[1:] - vals[:-1]\n",
    "    \n",
    "    X_rel = vals[1:] / vals[:-1]\n",
    "    X_rel[np.isnan(X_rel)] = 1\n",
    "    X_rel[np.isinf(X_rel)] = 1\n",
    "    \n",
    "    for start in tqdm.tnrange(0, len(loaded) - TICKS_IN_FIVE_MINUTES - PREDICT_DELAY_TICKS, GAP):\n",
    "        end = start + TICKS_IN_FIVE_MINUTES\n",
    "        end_part = start + TICKS_IN_FIVE_MINUTES * (DIVIDER - 1) // DIVIDER\n",
    "        \n",
    "        pooling = tuple(pool_func(array, axis=0) for pool_func in (np.min, np.max, np.mean, np.sum)\n",
    "                                                 for array in (X_diff[start:end-1],\n",
    "                                                               X_rel[start:end-1],\n",
    "                                                               X_diff[end_part:end-1],\n",
    "                                                               X_rel[end_part:end-1]\n",
    "                                                              ))\n",
    "        \n",
    "        simple = (X_diff[start:end-1:DIVIDER].flatten(), \n",
    "                  X_rel[start:end-1:DIVIDER].flatten(),\n",
    "                  X_diff[end_part:end-1].flatten(),\n",
    "                  X_rel[end_part:end-1].flatten()\n",
    "                 )\n",
    "        \n",
    "        X.append(np.hstack(simple + pooling))\n",
    "        y.append(target[end-1 + PREDICT_DELAY_TICKS] / target[end-1]  - 1)\n",
    "\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y(train_dataset)\n",
    "X_val, y_val = get_X_y(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pair in tqdm.tqdm_notebook(enumerate(utils.PAIR_NAMES)):\n",
    "    regr = lgb.LGBMRegressor(learning_rate=0.03, n_estimators=100, num_leaves=15, silent=False)\n",
    "    regr.fit(X_train, y_train[:, i])\n",
    "    with open(pair + '.pkl', 'wb+') as f:\n",
    "        pk.dump(regr, f)\n",
    "    \n",
    "    preds = regr.predict(X_val)\n",
    "    print(spearmanr(preds, y_val[:, i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
